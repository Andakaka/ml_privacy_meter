{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Shadow models audit for a PyTorch model trained on Purchase100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this tutorial, we will see:\n",
    "* How to create a Dataset object manually\n",
    "* How to audit a PyTorch model\n",
    "* How to use the ShadowMetric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from torch import nn, optim, Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "For now we install the library from the local source. A version will be pushed to pip soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///home/victor/ml_privacy_meter\n",
      "  Preparing metadata (setup.py) ... \u001B[?25ldone\n",
      "\u001B[?25hInstalling collected packages: privacy-meter\n",
      "  Attempting uninstall: privacy-meter\n",
      "    Found existing installation: privacy-meter 1.0\n",
      "    Uninstalling privacy-meter-1.0:\n",
      "      Successfully uninstalled privacy-meter-1.0\n",
      "  Running setup.py develop for privacy-meter\n",
      "Successfully installed privacy-meter-1.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -e ../.\n",
    "from privacy_meter.audit import Audit\n",
    "from privacy_meter.audit_report import PDFReport\n",
    "from privacy_meter.dataset import Dataset\n",
    "from privacy_meter.hypothesis_test import threshold_func\n",
    "from privacy_meter.information_source import InformationSource\n",
    "from privacy_meter.information_source_signal import ModelLoss\n",
    "from privacy_meter.metric import ShadowMetric\n",
    "from privacy_meter.model import PytorchModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Setting seed for reproducibility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Hyper parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_shadow_models = 2  # Number of shadow models to be trained\n",
    "epochs = 2          # Number of epochs for each model\n",
    "batch_size = 32      # Batch size for the trainings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Dataset creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's download the Purchase100 dataset (presented in https://www.cs.cornell.edu/~shmat/shmat_oak17.pdf on page 7) and extract it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-04-15 14:08:48--  https://github.com/privacytrustlab/datasets/raw/master/dataset_purchase.tgz\n",
      "Resolving github.com (github.com)... 20.205.243.166\n",
      "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/privacytrustlab/datasets/master/dataset_purchase.tgz [following]\n",
      "--2022-04-15 14:08:48--  https://raw.githubusercontent.com/privacytrustlab/datasets/master/dataset_purchase.tgz\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 22045876 (21M) [application/octet-stream]\n",
      "Saving to: ‘dataset_purchase.tgz’\n",
      "\n",
      "dataset_purchase.tg 100%[===================>]  21.02M  3.63MB/s    in 6.1s    \n",
      "\n",
      "2022-04-15 14:08:54 (3.45 MB/s) - ‘dataset_purchase.tgz’ saved [22045876/22045876]\n",
      "\n",
      "dataset_purchase\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/privacytrustlab/datasets/raw/master/dataset_purchase.tgz\n",
    "!tar -xvzf dataset_purchase.tgz\n",
    "!rm dataset_purchase.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We need to read the file and preprocess the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_purchase100():\n",
    "    \"\"\"\n",
    "    Cf. https://www.cs.cornell.edu/~shmat/shmat_oak17.pdf page 7\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    # Read raw dataset\n",
    "    dataset_path = \"dataset_purchase\"\n",
    "    with open(dataset_path, \"r\") as f:\n",
    "        purchase_dataset = f.readlines()\n",
    "    # Separate features and labels into different arrays\n",
    "    x, y = [], []\n",
    "    for datapoint in purchase_dataset:\n",
    "        split = datapoint.rstrip().split(\",\")\n",
    "        label = int(split[0]) - 1  # The first value is the label\n",
    "        features = np.array(split[1:], dtype=np.float32)  # The next values are the features\n",
    "        x.append(features)\n",
    "        y.append(label)\n",
    "    # Make sure the datatype is correct\n",
    "    x = np.array(x, dtype=np.float32)\n",
    "    # Convert labels into one hot vectors\n",
    "    y = OneHotEncoder(sparse=False).fit_transform(np.expand_dims(y, axis=1))\n",
    "    # Split data into train, test sets\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=1234)\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = preprocess_purchase100()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Then, we wrap the dataset into a Dataset object:\n",
    "* `data_dict` contains the actual dataset, in the form of a 2D dictionary. The first key corresponds to the split name (here we have two: \"train\" and \"test\"), and the second key to the feature name (here we also have two: \"x\" and \"y\").\n",
    "* `default_input` contains the name of the feature that should be used as the models input (here \"x\").\n",
    "* `default_output` contains the name of the feature that should be used as the label / models output (here \"y\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset = Dataset(\n",
    "    data_dict={'train': {'x': x_train, 'y': y_train}, 'test': {'x': x_test, 'y': y_test}},\n",
    "    default_input='x',\n",
    "    default_output='y'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Finally, we use the built-in `Dataset.subdivide()` function, to split the two splits (\"train\" and \"test\") into multiple sub-datasets (one per model). The resulting sub-splits are included in the parent object (\"train000\", \"train001\", etc.) and are returned as a list of individual Dataset objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "datasets_list = dataset.subdivide(\n",
    "    num_splits=n_shadow_models + 1,\n",
    "    delete_original=True,\n",
    "    in_place=True,\n",
    "    return_results=True,\n",
    "    method='hybrid',\n",
    "    split_size=10000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "================ DATASET OBJECT ================\n",
      "Splits            = ['train', 'test']\n",
      "Features          = ['x', 'y']\n",
      "Default features  = x --> y\n",
      "================================================\n",
      "1\n",
      "================ DATASET OBJECT ================\n",
      "Splits            = ['train', 'test']\n",
      "Features          = ['x', 'y']\n",
      "Default features  = x --> y\n",
      "================================================\n",
      "2\n",
      "================ DATASET OBJECT ================\n",
      "Splits            = ['train', 'test']\n",
      "Features          = ['x', 'y']\n",
      "Default features  = x --> y\n",
      "================================================\n"
     ]
    }
   ],
   "source": [
    "for i, d in enumerate(datasets_list):\n",
    "    print(i)\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's now define the pytorch models to be used: one target model, and `n_shadow_models` shadow models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "torch_models = [\n",
    "    nn.Sequential(\n",
    "        nn.Linear(in_features=600, out_features=128),\n",
    "        nn.Tanh(),\n",
    "        nn.Linear(in_features=128, out_features=100),\n",
    "        nn.Softmax(dim=1)\n",
    "    )\n",
    "    for _ in range(n_shadow_models + 1)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We define the loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "And we train each model on its split of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model #00, epoch #000:\ttrain_acc = 0.101\ttrain_loss = 4.539e+00\n",
      "model #00, epoch #001:\ttrain_acc = 0.278\ttrain_loss = 4.387e+00\n",
      "model #01, epoch #000:\ttrain_acc = 0.064\ttrain_loss = 4.564e+00\n",
      "model #01, epoch #001:\ttrain_acc = 0.189\ttrain_loss = 4.454e+00\n",
      "model #02, epoch #000:\ttrain_acc = 0.089\ttrain_loss = 4.547e+00\n",
      "model #02, epoch #001:\ttrain_acc = 0.283\ttrain_loss = 4.389e+00\n"
     ]
    }
   ],
   "source": [
    "for k, model in enumerate(torch_models):\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    x = dataset.get_feature(split_name=f'train{k:03d}', feature_name='<default_input>')\n",
    "    y = dataset.get_feature(split_name=f'train{k:03d}', feature_name='<default_output>')\n",
    "    n_samples = x.shape[0]\n",
    "    n_batches = ceil(n_samples / batch_size)\n",
    "    x = np.array_split(x, n_batches)\n",
    "    y = np.array_split(y, n_batches)\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss, acc = 0.0, 0.0\n",
    "        for b in range(n_batches):\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(Tensor(x[b]))\n",
    "            loss = criterion(Tensor(y[b]), y_pred)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            acc += torch.sum(y_pred.argmax(axis=1) == Tensor(y[b]).argmax(axis=1))\n",
    "        acc /= n_samples\n",
    "        epoch_loss /= n_samples\n",
    "        print(f'model #{k:02d}, epoch #{epoch:03d}:\\ttrain_acc = {acc:.3f}\\ttrain_loss = {epoch_loss:.3e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now that the models are all train, we can wrap each of them in a `PytorchModel` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "models = [\n",
    "    PytorchModel(\n",
    "        model_obj=model,\n",
    "        loss_fn=criterion\n",
    "    )\n",
    "    for model in torch_models\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Information Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can now define two InformationSource objects. Basically, an information source is an abstraction representing a set of models, and their corresponding dataset. Note that we could use the same `dataset` variable for the two InformationSource objects (each one would be queried on different splits of the dataset), but we also stored the sub-splits in different Dataset objects, so let's use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "target_info_source = InformationSource(\n",
    "    models=[models[0]],\n",
    "    datasets=[datasets_list[0]]\n",
    ")\n",
    "\n",
    "reference_info_source = InformationSource(\n",
    "    models=models[1:],\n",
    "    datasets=datasets_list[1:]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Metric and Audit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We now create a Metric object, which is an abstraction representing an algorithm used to measure something on an InformationSource, such as membership information leakage. In this case, we use the ShadowMetric to measure the membership information leakage of `target_info_source` in a black-box setting, using shadow models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "metric = ShadowMetric(\n",
    "    target_info_source=target_info_source,\n",
    "    reference_info_source=reference_info_source,\n",
    "    signals=[ModelLoss()],\n",
    "    hypothesis_test_func=threshold_func,\n",
    "    unique_dataset=False,\n",
    "    reweight_samples=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Finally, the Audit object is a wrapper to actually run the audit, and display the results. More visualization options will be added soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are stored in: /home/victor/ml_privacy_meter/docs/log_2022-04-15_14-09-16\n"
     ]
    }
   ],
   "source": [
    "audit = Audit(\n",
    "    metric=metric,\n",
    "    target_info_source=target_info_source,\n",
    "    reference_info_source=reference_info_source\n",
    ")\n",
    "audit.prepare()\n",
    "result = audit.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= METRIC RESULT OBJECT =============\n",
      "Accuracy          = 0.5185\n",
      "ROC AUC Score     = 0.524244515\n",
      "FPR               = 0.3661\n",
      "TN, FP, FN, TP    = (6339, 3661, 5969, 4031)\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several visualization tools are built in `privacy_tool`, such as ROC curves, signal values histogram, or confusion matrix. We can generate them individually, or generate a PDF report with all of them (note the `call_pdflatex` that you can switch on/off to automatically compile the .tex file locally)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "ename": "TemplateNotFound",
     "evalue": "../privacy_meter/report_files/report_template.tex",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTemplateNotFound\u001B[0m                          Traceback (most recent call last)",
      "Input \u001B[0;32mIn [33]\u001B[0m, in \u001B[0;36m<cell line: 5>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mprivacy_meter\u001B[39;00m\n\u001B[1;32m      3\u001B[0m privacy_meter\u001B[38;5;241m.\u001B[39maudit_report\u001B[38;5;241m.\u001B[39mREPORT_FILES_DIR \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m../privacy_meter/report_files\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m----> 5\u001B[0m \u001B[43mPDFReport\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate_report\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmetric_results\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mshadow_metric\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43mresult\u001B[49m\u001B[43m]\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43msystem_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mPurchase100 classifier\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfigures_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mshadow_metric\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mroc_curve\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mconfusion_matrix\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43msignal_histogram\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcall_pdflatex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\n\u001B[1;32m     10\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/ml_privacy_meter/privacy_meter/audit_report.py:264\u001B[0m, in \u001B[0;36mPDFReport.generate_report\u001B[0;34m(metric_results, figures_dict, system_name, call_pdflatex, show, save, filename_no_extension)\u001B[0m\n\u001B[1;32m    250\u001B[0m \u001B[38;5;66;03m# Configure jinja for LaTex and load template\u001B[39;00m\n\u001B[1;32m    251\u001B[0m latex_jinja_env \u001B[38;5;241m=\u001B[39m jinja2\u001B[38;5;241m.\u001B[39mEnvironment(\n\u001B[1;32m    252\u001B[0m     block_start_string\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mBLOCK\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m    253\u001B[0m     block_end_string\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m}\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    262\u001B[0m     loader\u001B[38;5;241m=\u001B[39mjinja2\u001B[38;5;241m.\u001B[39mFileSystemLoader(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mabspath(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[1;32m    263\u001B[0m )\n\u001B[0;32m--> 264\u001B[0m template \u001B[38;5;241m=\u001B[39m \u001B[43mlatex_jinja_env\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_template\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mREPORT_FILES_DIR\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m/report_template.tex\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    266\u001B[0m \u001B[38;5;66;03m# Render the template (i.e. generate the corresponding string)\u001B[39;00m\n\u001B[1;32m    267\u001B[0m latex_content \u001B[38;5;241m=\u001B[39m template\u001B[38;5;241m.\u001B[39mrender(\n\u001B[1;32m    268\u001B[0m     bib_file\u001B[38;5;241m=\u001B[39mos\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mabspath(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mREPORT_FILES_DIR\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/citations.bib\u001B[39m\u001B[38;5;124m'\u001B[39m),\n\u001B[1;32m    269\u001B[0m     image_folder\u001B[38;5;241m=\u001B[39mos\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mabspath(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m'\u001B[39m),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    275\u001B[0m     files_dict\u001B[38;5;241m=\u001B[39mfiles_dict\n\u001B[1;32m    276\u001B[0m )\n",
      "File \u001B[0;32m~/ml_privacy_meter/venv/lib/python3.8/site-packages/jinja2/environment.py:997\u001B[0m, in \u001B[0;36mEnvironment.get_template\u001B[0;34m(self, name, parent, globals)\u001B[0m\n\u001B[1;32m    994\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m parent \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    995\u001B[0m     name \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mjoin_path(name, parent)\n\u001B[0;32m--> 997\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_load_template\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mglobals\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/ml_privacy_meter/venv/lib/python3.8/site-packages/jinja2/environment.py:958\u001B[0m, in \u001B[0;36mEnvironment._load_template\u001B[0;34m(self, name, globals)\u001B[0m\n\u001B[1;32m    954\u001B[0m             template\u001B[38;5;241m.\u001B[39mglobals\u001B[38;5;241m.\u001B[39mupdate(\u001B[38;5;28mglobals\u001B[39m)\n\u001B[1;32m    956\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m template\n\u001B[0;32m--> 958\u001B[0m template \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloader\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmake_globals\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mglobals\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    960\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcache \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    961\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcache[cache_key] \u001B[38;5;241m=\u001B[39m template\n",
      "File \u001B[0;32m~/ml_privacy_meter/venv/lib/python3.8/site-packages/jinja2/loaders.py:125\u001B[0m, in \u001B[0;36mBaseLoader.load\u001B[0;34m(self, environment, name, globals)\u001B[0m\n\u001B[1;32m    121\u001B[0m     \u001B[38;5;28mglobals\u001B[39m \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m    123\u001B[0m \u001B[38;5;66;03m# first we try to get the source for this template together\u001B[39;00m\n\u001B[1;32m    124\u001B[0m \u001B[38;5;66;03m# with the filename and the uptodate function.\u001B[39;00m\n\u001B[0;32m--> 125\u001B[0m source, filename, uptodate \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_source\u001B[49m\u001B[43m(\u001B[49m\u001B[43menvironment\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    127\u001B[0m \u001B[38;5;66;03m# try to load the code from the bytecode cache if there is a\u001B[39;00m\n\u001B[1;32m    128\u001B[0m \u001B[38;5;66;03m# bytecode cache configured.\u001B[39;00m\n\u001B[1;32m    129\u001B[0m bcc \u001B[38;5;241m=\u001B[39m environment\u001B[38;5;241m.\u001B[39mbytecode_cache\n",
      "File \u001B[0;32m~/ml_privacy_meter/venv/lib/python3.8/site-packages/jinja2/loaders.py:194\u001B[0m, in \u001B[0;36mFileSystemLoader.get_source\u001B[0;34m(self, environment, template)\u001B[0m\n\u001B[1;32m    191\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_source\u001B[39m(\n\u001B[1;32m    192\u001B[0m     \u001B[38;5;28mself\u001B[39m, environment: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEnvironment\u001B[39m\u001B[38;5;124m\"\u001B[39m, template: \u001B[38;5;28mstr\u001B[39m\n\u001B[1;32m    193\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m t\u001B[38;5;241m.\u001B[39mTuple[\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mstr\u001B[39m, t\u001B[38;5;241m.\u001B[39mCallable[[], \u001B[38;5;28mbool\u001B[39m]]:\n\u001B[0;32m--> 194\u001B[0m     pieces \u001B[38;5;241m=\u001B[39m \u001B[43msplit_template_path\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtemplate\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    195\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m searchpath \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msearchpath:\n\u001B[1;32m    196\u001B[0m         filename \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(searchpath, \u001B[38;5;241m*\u001B[39mpieces)\n",
      "File \u001B[0;32m~/ml_privacy_meter/venv/lib/python3.8/site-packages/jinja2/loaders.py:35\u001B[0m, in \u001B[0;36msplit_template_path\u001B[0;34m(template)\u001B[0m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m piece \u001B[38;5;129;01min\u001B[39;00m template\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m     30\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m     31\u001B[0m         os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39msep \u001B[38;5;129;01min\u001B[39;00m piece\n\u001B[1;32m     32\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m (os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39maltsep \u001B[38;5;129;01mand\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39maltsep \u001B[38;5;129;01min\u001B[39;00m piece)\n\u001B[1;32m     33\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m piece \u001B[38;5;241m==\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mpardir\n\u001B[1;32m     34\u001B[0m     ):\n\u001B[0;32m---> 35\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m TemplateNotFound(template)\n\u001B[1;32m     36\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m piece \u001B[38;5;129;01mand\u001B[39;00m piece \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m     37\u001B[0m         pieces\u001B[38;5;241m.\u001B[39mappend(piece)\n",
      "\u001B[0;31mTemplateNotFound\u001B[0m: ../privacy_meter/report_files/report_template.tex"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import privacy_meter\n",
    "privacy_meter.audit_report.REPORT_FILES_DIR = '../privacy_meter/report_files'\n",
    "\n",
    "PDFReport.generate_report(\n",
    "    metric_results={\"shadow_metric\": [result]},\n",
    "    system_name=\"Purchase100 classifier\",\n",
    "    figures_dict={\"shadow_metric\": [\"roc_curve\", \"confusion_matrix\", \"signal_histogram\"]},\n",
    "    call_pdflatex=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}