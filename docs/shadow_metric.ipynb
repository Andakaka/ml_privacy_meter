{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Shadow models audit for a PyTorch model trained on Purchase100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this tutorial, we will see:\n",
    "* How to create a Dataset object manually\n",
    "* How to audit a PyTorch model\n",
    "* How to use the ShadowMetric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from torch import nn, optim, Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "For now we install the library from the local source. A version will be pushed to pip soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///home/victor/ml_privacy_meter\n",
      "  Preparing metadata (setup.py) ... \u001B[?25ldone\n",
      "\u001B[?25hInstalling collected packages: privacy-meter\n",
      "  Attempting uninstall: privacy-meter\n",
      "    Found existing installation: privacy-meter 1.0\n",
      "    Uninstalling privacy-meter-1.0:\n",
      "      Successfully uninstalled privacy-meter-1.0\n",
      "  Running setup.py develop for privacy-meter\n",
      "Successfully installed privacy-meter-1.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -e ../.\n",
    "from privacy_meter.audit import Audit\n",
    "from privacy_meter.dataset import Dataset\n",
    "from privacy_meter.hypothesis_test import threshold_func\n",
    "from privacy_meter.information_source import InformationSource\n",
    "from privacy_meter.information_source_signal import ModelLoss\n",
    "from privacy_meter.metric import ShadowMetric\n",
    "from privacy_meter.model import PytorchModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Setting seed for reproducibility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Hyper parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_shadow_models = 5  # Number of shadow models to be trained\n",
    "epochs = 15          # Number of epochs for each model\n",
    "batch_size = 32      # Batch size for the trainings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Dataset creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's download the Purchase100 dataset (presented in https://www.cs.cornell.edu/~shmat/shmat_oak17.pdf on page 7) and extract it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-04-15 13:34:04--  https://github.com/privacytrustlab/datasets/raw/master/dataset_purchase.tgz\n",
      "Resolving github.com (github.com)... 20.205.243.166\n",
      "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/privacytrustlab/datasets/master/dataset_purchase.tgz [following]\n",
      "--2022-04-15 13:34:04--  https://raw.githubusercontent.com/privacytrustlab/datasets/master/dataset_purchase.tgz\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... "
     ]
    }
   ],
   "source": [
    "!wget https://github.com/privacytrustlab/datasets/raw/master/dataset_purchase.tgz\n",
    "!tar -xvzf dataset_purchase.tgz\n",
    "!rm dataset_purchase.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We need to read the file and preprocess the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_purchase100():\n",
    "    \"\"\"\n",
    "    Cf. https://www.cs.cornell.edu/~shmat/shmat_oak17.pdf page 7\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    # Read raw dataset\n",
    "    dataset_path = \"dataset_purchase\"\n",
    "    with open(dataset_path, \"r\") as f:\n",
    "        purchase_dataset = f.readlines()\n",
    "    # Separate features and labels into different arrays\n",
    "    x, y = [], []\n",
    "    for datapoint in purchase_dataset:\n",
    "        split = datapoint.rstrip().split(\",\")\n",
    "        label = int(split[0]) - 1  # The first value is the label\n",
    "        features = np.array(split[1:], dtype=np.float32)  # The next values are the features\n",
    "        x.append(features)\n",
    "        y.append(label)\n",
    "    # Make sure the datatype is correct\n",
    "    x = np.array(x, dtype=np.float32)\n",
    "    # Convert labels into one hot vectors\n",
    "    y = OneHotEncoder(sparse=False).fit_transform(np.expand_dims(y, axis=1))\n",
    "    # Split data into train, test sets\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=1234)\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = preprocess_purchase100()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Then, we wrap the dataset into a Dataset object:\n",
    "* `data_dict` contains the actual dataset, in the form of a 2D dictionary. The first key corresponds to the split name (here we have two: \"train\" and \"test\"), and the second key to the feature name (here we also have two: \"x\" and \"y\").\n",
    "* `default_input` contains the name of the feature that should be used as the models input (here \"x\").\n",
    "* `default_output` contains the name of the feature that should be used as the label / models output (here \"y\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset = Dataset(\n",
    "    data_dict={'train': {'x': x_train, 'y': y_train}, 'test': {'x': x_test, 'y': y_test}},\n",
    "    default_input='x',\n",
    "    default_output='y'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Finally, we use the built-in `Dataset.subdivide()` function, to split the two splits (\"train\" and \"test\") into multiple sub-datasets (one per model). The resulting sub-splits are included in the parent object (\"train000\", \"train001\", etc.) and are returned as a list of individual Dataset objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "datasets_list = dataset.subdivide(\n",
    "    num_splits=n_shadow_models + 1,\n",
    "    delete_original=True,\n",
    "    in_place=True,\n",
    "    return_results=True,\n",
    "    method='hybrid',\n",
    "    split_size=10000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i, d in enumerate(datasets_list):\n",
    "    print(i)\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's now define the pytorch models to be used: one target model, and `n_shadow_models` shadow models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "torch_models = [\n",
    "    nn.Sequential(\n",
    "        nn.Linear(in_features=600, out_features=128),\n",
    "        nn.Tanh(),\n",
    "        nn.Linear(in_features=128, out_features=100),\n",
    "        nn.Softmax(dim=1)\n",
    "    )\n",
    "    for _ in range(n_shadow_models + 1)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We define the loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "And we train each model on its split of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for k, model in enumerate(torch_models):\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    x = dataset.get_feature(split_name=f'train{k:03d}', feature_name='<default_input>')\n",
    "    y = dataset.get_feature(split_name=f'train{k:03d}', feature_name='<default_output>')\n",
    "    n_samples = x.shape[0]\n",
    "    n_batches = ceil(n_samples / batch_size)\n",
    "    x = np.array_split(x, n_batches)\n",
    "    y = np.array_split(y, n_batches)\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss, acc = 0.0, 0.0\n",
    "        for b in range(n_batches):\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(Tensor(x[b]))\n",
    "            loss = criterion(Tensor(y[b]), y_pred)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            acc += torch.sum(y_pred.argmax(axis=1) == Tensor(y[b]).argmax(axis=1))\n",
    "        acc /= n_samples\n",
    "        epoch_loss /= n_samples\n",
    "        print(f'model #{k:02d}, epoch #{epoch:03d}:\\ttrain_acc = {acc:.3f}\\ttrain_loss = {epoch_loss:.3e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now that the models are all train, we can wrap each of them in a `PytorchModel` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "models = [\n",
    "    PytorchModel(\n",
    "        model_obj=model,\n",
    "        loss_fn=criterion\n",
    "    )\n",
    "    for model in torch_models\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Information Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can now define two InformationSource objects. Basically, an information source is an abstraction representing a set of models, and their corresponding dataset. Note that we could use the same `dataset` variable for the two InformationSource objects (each one would be queried on different splits of the dataset), but we also stored the sub-splits in different Dataset objects, so let's use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "target_info_source = InformationSource(\n",
    "    models=[models[0]],\n",
    "    datasets=[datasets_list[0]]\n",
    ")\n",
    "\n",
    "reference_info_source = InformationSource(\n",
    "    models=models[1:],\n",
    "    datasets=datasets_list[1:]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Metric and Audit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We now create a Metric object, which is an abstraction representing an algorithm used to measure something on an InformationSource, such as membership information leakage. In this case, we use the ShadowMetric to measure the membership information leakage of `target_info_source` in a black-box setting, using shadow models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "metric = ShadowMetric(\n",
    "    target_info_source=target_info_source,\n",
    "    reference_info_source=reference_info_source,\n",
    "    signals=[ModelLoss()],\n",
    "    hypothesis_test_func=threshold_func,\n",
    "    unique_dataset=False,\n",
    "    reweight_samples=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Finally, the Audit object is a wrapper to actually run the audit, and display the results. More visualization options will be added soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "audit = Audit(\n",
    "    metric=metric,\n",
    "    target_info_source=target_info_source,\n",
    "    reference_info_source=reference_info_source\n",
    ")\n",
    "audit.prepare()\n",
    "print(audit.run())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}