run: # Configurations for a specific run
  random_seed: 12345 # Integer number of specifying random seed
  log_dir: temp_test # String for indicating where to save all the information, including models and computed signals. We can reuse the models saved in the same log_dir.

audit: # Configurations for auditing
  privacy_game: privacy_loss_model # Indicate the privacy game from privacy_loss_model, avg_privacy_loss_training_algo, privacy_loss_sample
  device: cpu # String for indicating on which device we conduct the membership inference attack and train reference models.
  audit_batch_size: 1000 # Integer number for indicating the batch size for computing signals in the privacy meter.
  algorithm: population # String for indicating the membership inference attack. We currently support population, reference.
  report_log: report_population # String that indicates the folder where we save the and auditing report.
  key: none # String for indicating the meaning of the idx. We support data_idx and none for reusing existing reference models. data_idx search for models which include or exclude the data point indicated using idx. Otherwise, the reference models are the ones that have the same training setting as indicated above.
  idx: none # Integer number for the model index or data index.

train: # Configuration for training
  type: pytorch # Training framework (we only support pytorch now).
  epochs: 30 # Integer number for indicating the epochs for training target model.
  batch_size: 16 # Integer number for indicating batch size for training the target model.
  test_batch_size: 10000 # Integer number for indicating batch size for evaluating the target model.
  optimizer: Adam # String which indicates the optimizer. We support Adam and SGD.
  lr: 0.001 # Float number for indicating learning rate for training the target model.
  wd: 0 # Float number for indicating weight decay for training the target model.
  model_name: CNN # String for indicating the model type. We support CNN. More model types can be added in model.py.
  device: cpu # String for indicating the device we want to use for training models.
  key: none # String for indicating the meaning of the idx. We support data_idx, model_idx or none.
  num_target_model: 1 #Integer number for indicating how many target models we want to audit for the privacy game

data: # Configuration for data
  dataset: cifar10 # String indicates the name of the dataset
  f_train: 0.041666666666666664 # Float number from 0 to 1 indicating the fraction of the train dataset
  f_test: 0.041666666666666664 # Float number from 0 to 1 indicating the fraction of the test dataset
  split_method: no_overlapping # String for indicating the methods of splitting the dataset between train, test, and auditing. Note that, compare to the baseline, we don't use the class balanced splitting.
  f_audit: 0.06666666666666667 # Float from 0 to 1, indicating the fraction of the auditing dataset
  data_dir: data # String about where to save the data.

## Expected time:
# 2023-01-17 17:33:12 INFO     Prepare the datasets costs 35.29921531677246 seconds
# 2023-01-17 17:33:31 INFO     Prepare 0-th target model costs 18.66761589050293 seconds: Train accuracy 0.7548, Train Loss 0.701645558996565; Test accuracy 0.422, Test Loss 1.9637681245803833
# 2023-01-17 17:33:31 INFO     Prepare the target model costs 18.669411182403564 seconds
# 2023-01-17 17:33:31 INFO     Prepare the information source costs 0.18801140785217285 seconds
# 2023-01-17 17:33:31 INFO     Prepare privacy meter results costs 0.14173245429992676 seconds
# 2023-01-17 17:33:34 INFO     Prepare the plot for the privacy risk report costs 3.0044233798980713 seconds
# 2023-01-17 17:33:34 INFO     Run the priavcy meter for the all steps costs 57.303576946258545 seconds

## Expected outcome:
# AUC: 0.713
