run: # the configurations for the running setup
  random_seed: 1234 # random seed for each run
  log_dir: demo_all # where to save all the information, including models and computed signals 

audit: # the configurations for the MIA
  privacy_game: privacy_loss_sample #privacy_loss_model #avg_privacy_loss_training_algo # the configuarations for the privacy loss game
  device: cuda:1 # indicate on which device we conduct the MIA
  audit_batch_size: 1000 # the batch size for computing signals for inferring membership information
  algorithm: reference # the algorithm used for inferring membership information
  num_reference_models: 2 # if reference attack is used, this indicates the number of reference models we train.
  batch_size: 64 # it indicates the batch size for training reference models
  f_reference_dataset: 1 # this indicates the ratio between the reference train dataset and the target train dataset
  optimizer: Adam # the following arguments indicating the optimizers setting
  lr: 0.001
  wd: 0
  model_name: CNN # the model name for reference models 
  epochs: 30  # training epochs for training reference models
  report_log: report_sample # where to save the auditing results
  split_method: uniform # spliting methods among reference datasets
  idx: 1 # audit which dataset points


train: # the configuarations for the training
  type: pytorch
  epochs: 30
  batch_size: 64
  test_batch_size: 10000
  optimizer: Adam
  lr: 0.001
  wd: 0
  model_name: CNN
  device: cuda:1
  key: data_idx # we support data_idx and none for reusing existing reference models. data_idx search for models which include or exclude the data point indicated using idx. Otherwise, the reference models are the ones which have the same training setting as indicated above.
  idx: 1 # include which data point
  num_in_models: 40 #indicate how many target models trained on idx 
  num_out_models: 40 #indicate how many target models not trained on idx 


data:  # the configuarations for the dataset
  dataset: cifar10
  f_train: 0.3
  f_test: 0.3
  split_method: uniform # how to sample the auditing dataset 
  f_audit: 0.3  # when it is uniformly sampled from the dataset 